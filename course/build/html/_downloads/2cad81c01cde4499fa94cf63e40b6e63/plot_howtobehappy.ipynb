{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Happy world\n\n**What we will learn:** Plotting data and looking for relationships.\nFitting straight lines to data. Understanding the slope and intercept of the line as parameters. \nShowing that the parameters are the best possible fit to the data.\n\n**Good to know beforehand:** [Scatter diagrams](https://www.bbc.co.uk/bitesize/guides/znjv4wx/revision/1) ; \n[Equation for a straight line](https://www.bbc.co.uk/bitesize/guides/zt8sgk7/revision/1) ; \n[Differentiation](https://www.bbc.co.uk/bitesize/guides/zyj77ty/revision/1)\n\n## Plotting the data\n\nEvery year since 2005, the World Happiness Report has analysed the results of the Gallup World Poll, \nwhich is carried out in 160 countries (covering 99% of the world\u2019s population). \nThe pollsters contact a random sample of people in each country and ask them over \n100 questions \u2013 about their income, their health and their family. These questions include the \nfollowing question about happiness:::\n\nAll things considered, how satisfied are you with your life as a whole these days? Use a 0 to 10 scale, \nwhere 0 is dissatisfied and 10 is satisfied to give your answer.\n\nPeople living in different countries give different answers. In the UK is 6.94, making the UK 17th in the world for happiness. \nThe top ranked country \u2013 rather surprisingly given a national stereotype of people who are reserved and don\u2019t express their \nfeelings very much \u2013 is Finland, with a score of 7.82. In general, Scandinavian and Northern European countries are \nranked highest. The USA is 16th (0.03 points ahead of the UK). China, with a score of 5.59 and at 72nd place, is \nroughly in the middle of the table of the countries surveyed. Other mid-ranked countries include Montenegro, Ecuador, \nVietnam and Russia. Further down the table, we find many African \u2013 Uganda and Ethiopia placed 117th and 131st, \nrespectively \u2013 and Middle Eastern countries \u2013 Iran is at 110 and Yemen at 132.  \nThe unhappiest country in the world in 2022 is Afghanistan, with an average happiness score of only 2.40.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\n\n# Read in the data\nhappy = pd.read_csv(\"../data/HappinessData.csv\",delimiter=';') \nhappy.rename(columns = {'Social support':'SocialSupport'}, inplace = True) \nhappy.rename(columns = {'Life Ladder': 'Happiness'}, inplace = True) \nhappy.rename(columns = {'Perceptions of corruption':'Corruption'}, inplace = True) \nhappy.rename(columns = {'Log GDP per capita': 'LogGDP'}, inplace = True) \nhappy.rename(columns = {'Healthy life expectancy at birth': 'LifeExp'}, inplace = True) \nhappy.rename(columns = {'Freedom to make life choices': 'Freedom'}, inplace = True) \n\n# We just look at data for 2018 and dsiplay in table.\ndf=happy.loc[happy['Year'] == 2018]\ndisplay(df[['Country name','LifeExp','Happiness']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the data \nThe code below plots the average life expectancy of \neach of these countries against their happiness (life ladder) scores. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pylab import rcParams\nrcParams['figure.figsize'] = 14/2.54, 14/2.54\nmatplotlib.font_manager.FontProperties(family='Helvetica',size=11)\n\n\ndef plotData(df,x,y): \n    fig,ax=plt.subplots(num=1)\n    ax.plot(x,y, data=df, linestyle='none', markersize=5, marker='o', color=[0.85, 0.85, 0.85])\n    for country in ['United States','United Kingdom','Croatia','Benin','Finland','Yemen']:\n        ci=np.where(df['Country name']==country)[0][0]\n        ax.plot(  df.iloc[ci][x],df.iloc[ci][y], linestyle='none', markersize=7, marker='o', color='black')\n        ax.text(  df.iloc[ci][x]+0.5,df.iloc[ci][y]+0.08,  country)\n           \n    ax.set_xticks(np.arange(30,90,step=5))\n    ax.set_yticks(np.arange(11,step=1))\n    ax.set_ylabel('Average Happiness (0-10)')\n    ax.set_xlabel('Life Expectancy at Birth')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.set_xlim(47,78)\n    ax.set_ylim(2.5,8.1) \n    return fig,ax\n\nfig,ax=plotData(df,'LifeExp','Happiness')\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each circle in the plot is a country. \nThe x-axis shows the life expectancy in the country and \nthe y-axis shows the average ranking of life-satisfaction, \non the 0 to 10 scale. In general, the higher the life expectancy of a country, \nthe higher the happiness there. \n\n## Drawing a line through the data \n\nOne way to quantify this relationship is to draw a straight line\nthrough the points, showing how happiness increases with life expectancy. \nFor example, imagine that for every 12 extra years which people live in a \ncountry they are one point happier. The equation for happiness in this case \nwould then look like this,\n\n\\begin{align}\\mbox{Happiness} = \\frac{\\mbox{Life Expectancy}}{12}\\end{align}\n\nFor example, if the average life expectancy in the country \nis 60 then the equation above predicts the happiness to be 60/12=5. \nIf the life expectancy is 78 then average happiness will be 78/12=6.5. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We can draw this equation in the form of a straight line going \n# through the cloud of country points, as shown below.\n\nfig,ax=plotData(df,'LifeExp','Happiness')\n\n# Setup parameters \n# a is the lines intercept\n# b is the slope of the line\n# and calculate a line\nm=1/12\nLife_Expectancy=np.arange(0.5,100,step=0.01)\nHappiness= m*Life_Expectancy\n\nax.plot(Life_Expectancy, Happiness, linestyle='-', color='black')\ndf=df.assign(Predicted=np.array(m*df['LifeExp']))\nfor country in ['United States','United Kingdom','Croatia','Benin','Finland','Yemen']:\n    ci=np.where(df['Country name']==country)[0][0]\n    ax.plot(  [df.iloc[ci]['LifeExp'],df.iloc[ci]['LifeExp']] ,[ df.iloc[ci]['Happiness'],df.iloc[ci]['Predicted']] ,linestyle=':', color='black')\n \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try changing the slope and the intercept of the line above by \nchanging the values 0 and 1/12 in the code above and replotting the line.\nSee if you can find a line that lies closer to the data points.\n\nEach of the dotted lines show how far the prected line \u2013 which predicts that happiness is one \ntwelfth of life expectancy \u2013 is from the data for each of the six highlighted countries.\nFor example, the USA has a happiness score of 6.88 and an \naverage life expectancy of 68.3. The first equation (figure 2b) predicts \n\n\\begin{align}\\mbox{Predicted USA Happiness} = \\frac{\\mbox{USA Life Expectancy}}{12} = \\frac{\\mbox{68.3}}{12} =  5.69\\end{align}\n\nWhich means that the squared distance between the prediction and reality is \n\n\\begin{align}\\end{align}\n\n (6.88 - 5.69)^2 = 1.412\n\nThe table below shows the predicted value and the squared distance between \nprediction and reality for each country. We then sum these squared distances \nto get an overall measure of how far our predictions our from reality. This is done below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df=df.assign(SquaredDistance=np.power((df['Predicted'] - df['Happiness']),2))\ndisplay(df[['Country name','Happiness','Predicted','SquaredDistance']])\n             \nModel_Sum_Of_Squares = np.sum(df['SquaredDistance'])\n\nprint('The model sum of squares is %.4f' % Model_Sum_Of_Squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The question is whether this line is the \u2018best\u2019 line? You can test to see if you get a line\nwhich is closer to the data, by changing a and b above and seeing if the sum of squares gets smaller.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding the best fit line \nLet\u2019s start by formulating this problem mathematically. \nFor each country $i$, \nwe have two values: the life satisfaction, which I will call $y_i$ \nand life expectancy, which I will call $x_i$ . For example, \nwhen $i=$USA then $x_i=6.88$ and $y_i=68.3$. \n\nNow, let\u2019s denote the slope of the line as $m$ (in the plot above\n$m=1/12$) and repeat the caluclation we made above but with letters instead \nof numbers. First we note that \n\n\\begin{align}\\end{align}\n\n \\hat{y_i} = m \\cdot x_i = 1/12 \\cdot 6.88\n\nThe little \"hat\" in $\\hat{y_i}$ denotes that it is a prediction \n(rather than the measured value itself, which is $y_i$). \nThe squared distance between the prediction and outcome is written as\n\n\\begin{align}\\end{align}\n\n ( y_i - m \\cdot x_i)^2 \n\nI want to emphasise here that all I am doing is rewriting the same calculation I\ndid above with numbers, but now with the letters. The reason for doing this is that \nour aim is to find an equation for the value of $m$ which minimises the sum of square \ndistances.\n\nThe next step is to write out the sum\n\n\\begin{align}\\end{align}\n\n ( y_1 - m \\cdot x_1)^2 +  ( y_2 - m \\cdot x_2)^2  + ... + ( y_{136} - m \\cdot x_{136})^2  \n\nThe above equation is can be written in shorthand form as\n\n\\begin{align}\\end{align}\n\n \\sum_i^n ( y_i - m \\cdot x_i)^2 \n\nwhere $n=136$ is the number of countries. \n\nWe want to find the value of $m$ which minimises this sum of squares. But how do we do this?\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A diversion in to differentiation\nThis part of the webpage assumes you have studied differentiation \nand you understand that the derivative is about finding an equation\nfor the slope of a curve. When the derivative is zero, the slope is zero.\n\nTo refresh your memory, imagine you are asked to find the value \nof $m$ which minimises the \nfunction $(4-2m)^2$. To solve this problem, you can first multiply out \nthe brackets to get\n\n\\begin{align}\\end{align}\n\n (4-2m)^2 = 16 - 16m + 4m^2 \n\nYou can then take a derivative in order to calculate the slope of the function, \nas follows.\n\n\\begin{align}\\end{align}\n\n \\frac{d}{dm} 16 - 16m + 4m^2= - 16 + 8m\n\nWe then solve this equal to zero, \nbecause the function is a minimum when it has slope zero.\n\n\\begin{align}- 16 + 8m = 0 \\Rightarrow 8m = 16 \\Rightarrow m = 2\\end{align}\n\nProblem solved. \n\nAlthough  the algebra is more complicated, we can use exactly the same logic to solve the problem \nabove, of finding the value of $m$ which minimises this sum of squares. We first\ntake the derivative \n\n\n\\begin{align}\\end{align}\n\n \\frac{d}{dm} \\left( ( y_1 - m \\cdot x_1)^2 +  ( y_2 - m \\cdot x_2)^2  + ... + ( y_{136} - m \\cdot x_{136})^2  \\right)\n\n = - 2 x_1 y_1 + 2 x_1^2 m  - 2 x_2 y_2 + 2 x_2^2 m  +  ... - 2 x_{136} y_{136} + 2 x_{136}^2 m  \n\nAgain, although this particular step involves alot of algebra, notice that we are doing exactly the same as in the example above.\nAnother thing that can confuse students (when I teach this in statistics) is that we differentiate with respect to $m$. \nIn school, we often use the letter $x$ for the variable name and $m$ for a constant. Here it is the other way round. \nThe data $x_i$ and $y_i$ are constants (measurements from countries) and  $m$ is the variable we differentiate for.\n\nWe now write the sum above in shorthand as\n\n\\begin{align}\\end{align}\n\n \\sum_i^n 2 x_i y_i - \\sum_i^n 2 \\cdot x_i^2 m\n\nand we solve equal to zero (to find the point at which it is mimized, and the slope is zero) to get\n\n\\begin{align}\\end{align}\n\n \\sum_i^n 2 x_i y_i - \\sum_i^n 2 \\cdot x_i)^2 m = 0 \\Rightarrow \\sum_i^n 2 x_i y_i = \\sum_i^n 2 \\cdot x_i^2 m \\Rightarrow \\sum_i^n x_i y_i = \\sum_i^n x_i^2\n\nMoving the $m$ to the left hand side gives\n\n\\begin{align}\\end{align}\n\n m = \\frac{\\sum_i^n x_i y_i}{\\sum_i^n x_i^2}\n\nLets now use our newly found equation to calculate the line that best fits the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df=df.assign(SquaredLifEExp=np.power(df['LifeExp'],2))\ndf=df.assign(HappinessLifEExp=df['LifeExp'] * df['Happiness'])\n\nm_best = np.sum(df['HappinessLifEExp'])/np.sum(df['SquaredLifEExp'])\nprint('The best fitting line has slope m = %.4f' % m_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our intial guess of $m = 1/12 = 0.0833$ wasn't so far away from the best fitting value. \nBut this new slope is slightly closer to the data. We can now plot this and recalculate the model sum of squares\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Life_Expectancy=np.arange(0.5,100,step=0.01)\nHappiness= m_best*Life_Expectancy\n\nfig,ax=plotData(df,'LifeExp','Happiness')\nax.plot(Life_Expectancy, Happiness, linestyle='-', color='black')\ndf=df.assign(Predicted=np.array(m_best*df['LifeExp']))\nfor country in ['United States','United Kingdom','Croatia','Benin','Finland','Yemen']:\n    ci=np.where(df['Country name']==country)[0][0]\n    ax.plot(  [df.iloc[ci]['LifeExp'],df.iloc[ci]['LifeExp']] ,[ df.iloc[ci]['Happiness'],df.iloc[ci]['Predicted']] ,linestyle=':', color='black')\n \nplt.show()\n\ndf=df.assign(SquaredDistance=np.power((df['Predicted'] - df['Happiness']),2))\n             \nModel_Sum_Of_Squares = np.sum(df['SquaredDistance'])             \nprint('The model sum of squares is %.4f' % Model_Sum_Of_Squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, this sum of squares is slightly smaller than the value we got above \nfor $m = 1/12$ \n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Including the Intercept\n\nLet's start by shifting the data so that it has a mean (average) of zero.\nTo do this we simply take away the mean value from both life expectancy and \nfrom happiness. Then replot the data \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df=df.assign(ShiftedLifeExp=df['LifeExp'] - np.mean(df['LifeExp']))\ndf=df.assign(ShiftedHappiness=df['Happiness'] - np.mean(df['Happiness']))\n\nfig,ax=plotData(df,'ShiftedLifeExp','ShiftedHappiness')\nax.set_ylabel('Happiness (corrected for Mean Happiness)')\nax.set_xlabel('Life Expectancy (corrected for Mean Life Expectancy) ')\nax.set_xticks(np.arange(-30,30,step=5))\nax.set_yticks(np.arange(-5,5,step=1))\nax.set_xlim(-20,15)\nax.set_ylim(-3,3) \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This graph shows us that, for example, Yemen is almost -2.5 points below the world \naverage for happiness and has a life expectency 8 years shorter than the average over\nall countries in the world. The United States life expectancy is around 3.5 years longer than \nthe average and the citizens of the USA are about 1.3 points happier than average.\nIt is worth noting that the correction is for country averages and does not account for the size of the \npopulations of these various countries. It does though give us a new way \nof seeing between country differences.\n\n\nLet's now try to find the best fit line which goes through these data points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df=df.assign(SquaredLifEExp=np.power(df['ShiftedLifeExp'],2))\ndf=df.assign(HappinessLifEExp=df['ShiftedLifeExp'] * df['ShiftedHappiness'])\n\nm_best = np.sum(df['HappinessLifEExp'])/np.sum(df['SquaredLifEExp'])\nprint('The best fitting line has slope m = %.4f' % m_best)\n\nLife_Expectancy=np.arange(-50,50,step=0.01)\nHappiness= m_best*Life_Expectancy\n\nfig,ax=plotData(df,'ShiftedLifeExp','ShiftedHappiness')\nax.plot(Life_Expectancy, Happiness, linestyle='-', color='black')\nax.set_ylabel('Happiness (corrected for Mean Happiness)')\nax.set_xlabel('Life Expectancy (corrected for Mean Life Expectancy) ')\nax.set_xticks(np.arange(-30,30,step=5))\nax.set_yticks(np.arange(-5,5,step=1))\nax.set_xlim(-20,15)\nax.set_ylim(-3,3) \n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This line appears to fit better than the one we fitted earlier! It seems \nto lie closer to the points and better capture the relationship in the data.\nTo test whether this is indeed the case we can calculate the sum of squares\nbetween this new line and the shifted data. This is as follows\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df=df.assign(Predicted=np.array(m_best*df['ShiftedLifeExp']))       \ndf=df.assign(SquaredDistance=np.power((df['Predicted'] - df['ShiftedHappiness']),2))\n            \nModel_Sum_Of_Squares = np.sum(df['SquaredDistance'])             \nprint('The model sum of squares is %.4f' % Model_Sum_Of_Squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This new line through the data is better! It has a smaller sum of squares. \n\nThe mean values are calculated as follows\n\n\\begin{align}\\end{align}\n\n \\bar{x} = \\frac{1}{n} \\sum_i^n x_i \\mbox{ and }  \\bar{y} = \\frac{1}{n} \\sum_i^n y_i \n\n\nUsing this notation, the equation for the line through the data is\n\n\\begin{align}\\end{align}\n\n \\hat{y_i} - \\bar{y} = m  (\\hat{x_i} - \\bar{x})\n\nJust to remind you about the notation. The predicted value has a hat over it, while the mean values\nhave a bar over them. We can rearrange this equation to get \n\n\\begin{align}\\end{align}\n\n \\hat{y_i}  = m \\hat{x_i} + (\\bar{y} - m\\bar{x})\n\nNotice that this is an equation for a straight line, so we can write\n\n\\begin{align}\\end{align}\n\n \\hat{y_i}  = m \\hat{x_i} + k  \\mbox{ where } k = \\bar{y} - m\\bar{x}\n\nLet's apply this to data and plot the line again\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "k_best = np.mean(df['Happiness']) - m_best*np.mean(df['LifeExp'])\n\nLife_Expectancy=np.arange(0.5,100,step=0.01)\nHappiness= m_best*Life_Expectancy + k_best\n\nfig,ax=plotData(df,'LifeExp','Happiness')\nax.plot(Life_Expectancy, Happiness, linestyle='-', color='black')\ndf=df.assign(Predicted=np.array(m_best*df['LifeExp']+k_best))\nfor country in ['United States','United Kingdom','Croatia','Benin','Finland','Yemen']:\n    ci=np.where(df['Country name']==country)[0][0]\n    ax.plot(  [df.iloc[ci]['LifeExp'],df.iloc[ci]['LifeExp']] ,[ df.iloc[ci]['Happiness'],df.iloc[ci]['Predicted']] ,linestyle=':', color='black')\n \nplt.show()\n\nprint('The slope of the line is m = %.4f and the intercept is k = %.4f' % (m_best,k_best))\nprint('An increase in life expectancy of %.4f years is associated with one extra point of happiness' % (1/m_best))\n\n    \ndf=df.assign(SquaredDistance=np.power((df['Predicted'] - df['Happiness']),2))          \nModel_Sum_Of_Squares = np.sum(df['SquaredDistance'])             \nprint('The model sum of squares is still %.4f' % Model_Sum_Of_Squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have it. By shifting back to the original co-ordinates we\ncan find the best fitting line through the data. Notice that the sum of squares is unaffected by\nshifting the line back again, since the distances from the points to the line are unaffected. \n\nWe can say (roughly speaking) that for every 8 years of life expectancy\ncountry citizens are about 1 point happier on a scale of 0 to 10. It isn't \nthe whole truth, but it isn't entirely misleading either. \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Maximum likelihood\n\nIn section . We have found that the values of parameters $k$ and $m$ that\nminimise the square distance to the line, but are these the maximum likelihood estimates?\n\nSee [here](https://www.math.arizona.edu/~jwatkins/n-mle.pdf)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}