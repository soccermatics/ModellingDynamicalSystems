{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# ARMA model \n\n\n## The moving average\n\nThe code below simulates the moving average model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom pylab import rcParams\nmatplotlib.font_manager.FontProperties(family='Helvetica',size=11)\nrcParams['figure.figsize'] = 14/2.54, 14/2.54\n\n\ndef plotOverTime(ax, w):\n    n=len(w)\n    t=np.arange(n)\n    ax.plot(t,w, '-',color='k')\n    ax.set_xlabel('Time: t')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.set_xticks(np.arange(0,n,step=n/5))\n    ax.set_yticks(np.arange(-n,n+1,step=10))\n    ax.set_xlim(0,n)\n    ax.set_ylim(-2*np.sqrt(n),2*np.sqrt(n)) \n\n\ndef MA(w0,steps,c_vals,sigma=1):\n    # n step random walk\n    w = w0\n    w_k = np.zeros(steps)\n    \n    #The random values can be produced in advance\n    e_k = np.random.normal(0, 1,steps) \n    \n    for k in range(steps):\n        w_k[k]= w\n        \n        #Add the most recent value\n        w = e_k[k]\n        \n        #Add the weighted average of older values\n        for j,c in enumerate(c_vals):\n            w += c*e_k[k-j-1]  \n        \n    return w_k\n\n\nfig,axs=plt.subplots(3,3)\nsteps=100\nfor axsr in axs:\n    for j,ax in enumerate(axsr):\n        w=MA(0,steps,[0.5])\n        plotOverTime(ax, w)\n        if j==0:\n            ax.set_ylabel('Position: w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This process doesn't move far from zero, because it has no \"memory\".\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autogressive model \n\nHere we plot the AR(1) model with $a_1=-0.9$. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def AR(w0,steps,a_vals,sigma=1):\n    # n step random walk\n    \n    n=len(w0)\n    \n    #Setup intial conditions\n    w_k = np.zeros(steps)\n    w_k[0:n-1] = w0\n    \n    #The random values can be produced in advance\n    e_k = np.random.normal(0, 1,steps) \n    \n    for k in range(n,steps):\n        \n        #Add the noise\n        w = e_k[k]\n        \n        #Add the weighted average of older values\n        for j,a in enumerate(a_vals):\n            w += -a*w_k[k-j-1]  \n        \n        w_k[k]= w\n        \n    return w_k\n\n\n\nfig,axs=plt.subplots(3,3)\nsteps=30\na_vals = [-0.9]\nfor axsr in axs:\n    for j,ax in enumerate(axsr):\n        w=AR([0],steps,a_vals)\n        plotOverTime(ax, w)\n        if j==0:\n            ax.set_ylabel('Position: w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now there is a longer memory. The process increases and decreases\nmore slowly in comparison to the fluctuations caused by noise.\n\nWhen we reduce  $a_1$ then the process moves more randomly, like \nthe random walk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig,axs=plt.subplots(3,3)\nsteps=30\na_vals = [-0.1]\nfor axsr in axs:\n    for j,ax in enumerate(axsr):\n        w=AR([0],steps,a_vals)\n        plotOverTime(ax, w)\n        if j==0:\n            ax.set_ylabel('Position: w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If $a_1$ is positive then the process oscilates backwards and forwards.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig,axs=plt.subplots(3,3)\nsteps=30\na_vals = [0.9]\nfor axsr in axs:\n    for j,ax in enumerate(axsr):\n        w=AR([0],steps,a_vals)\n        plotOverTime(ax, w)\n        if j==0:\n            ax.set_ylabel('Position: w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Theoretical covariance \n\nThe covariance functionfor AR(1) is calcuated as follows.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def R_theoretical(a_vals,maxtau,sigma=1):\n    R = np.zeros(maxtau)\n    for tau in range(maxtau):\n        R[tau] = np.power(-a_vals[0],tau)* (np.power(sigma,2)/(1-np.power(a_vals[0],2)))\n\n    return R\n\nrcParams['figure.figsize'] = 14/2.54, 6/2.54\n\nfig,axs=plt.subplots(1,3)\nfor i,avals in enumerate([[-0.9],[-0.1],[0.9]]):\n\n    ax=axs[i]\n    if (i==0):\n        ax.set_ylabel('Covariance: R')\n    txt='a_1=%.2f'%avals[0]\n    ax.set_title(txt)\n    R=R_theoretical(avals,maxtau=steps)\n    plotOverTime(ax, R)\n    ax.set_yticks(np.arange(-10,10,step=2))\n    ax.set_ylim(-7,7) \n    \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Empirical covariance \n\nCorrect the code below to\nwrite a function yourself to calculate the empirical covariance. \n\nThen use it to calculate the standard deviation over 1000 time steps of an\nAR(1) model with $a_1=-0.9$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def R_empirical(w,maxtau):\n    \n    steps=len(w)\n    R = np.zeros(maxtau)\n    for tau in range(maxtau):\n        Rk = np.zeros(steps)\n        for k,wk in enumerate(w):\n            if k<steps-tau:\n                Rk[k] =  0\n           \n        R[tau] = 0\n        \n            \n    return R\n\nfig,ax=plt.subplots(1)\nax.set_ylabel('Covariance: R')\na_vals = [-0.9]\nsteps=1000\nw=AR([0],steps,a_vals)\nR=R_empirical(w,maxtau=50)\nplotOverTime(ax, R)\nax.set_yticks(np.arange(-10,10,step=1))\nax.set_ylim(-2,7) \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Share prices\n\nNow let's use your function to calulate a covariance function for H&M share \nprices. First lets load in and plot the data. \n\nYou can download the data file here:\n\n[HandM.csv](https://github.com/soccermatics/ModellingDynamicalSystems/blob/main/course/lessons/data/HandM.csv)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\nshare_prices=pd.read_csv('../data/HandM.csv')\nw = share_prices['Average price']\nw=np.array(w.dropna())\nfig,ax=plt.subplots(1)\n\nw=w-np.mean(w)\nplotOverTime(ax, w)\nax.set_ylabel('Price (relative to June 2019): w')\nax.set_ylim(-75,75) \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Share prices\n\nNow plot the covariance using your empirical function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}